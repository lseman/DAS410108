{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "# Physics-Informed Neural Networks (PINNs) in PyTorch: Familiar Examples Tutorial\n",
        "\n",
        "Absolutely! Great ideaâ€”students often find electrical circuits and heat transfer more intuitive than fluid dynamics. We'll adapt the PINN framework to two classic problems they're likely familiar with from intro physics/engineering courses:\n",
        "\n",
        "1. **Kirchhoff's Voltage Law (KVL) for an RC Circuit**: This leads to a simple **ordinary differential equation (ODE)** for the capacitor voltage decay. It's a 1D time-domain problem.\n",
        "2. **1D Heat Diffusion Equation**: The classic **heat equation**, a linear PDE modeling temperature evolution in a rod.\n",
        "\n",
        "These showcase PINNs for both ODEs (easier entry) and PDEs. We'll keep the structure similar to the Burgers' tutorial: PyTorch-based, with automatic differentiation, Adam + LBFGS optimization, and visualizations. Each section is self-containedâ€”run them independently in a Jupyter notebook.\n",
        "\n",
        "Assumptions: Students know basic PyTorch, ODEs/PDEs, and circuits/heat transfer. Runtime: ~1-2 minutes per example on CPU.\n",
        "\n",
        "## Quick PINN Recap\n",
        "PINNs approximate solutions $ u(\\mathbf{x}) $ (e.g., voltage or temperature) with a neural net, trained to minimize:\n",
        "- **Data loss**: Matches initial/boundary conditions.\n",
        "- **Physics loss**: PDE/ODE residual â‰ˆ 0 at random \"collocation\" points.\n",
        "\n",
        "## Example 1: RC Circuit ODE (Kirchhoff's Law)\n",
        "### Problem Setup\n",
        "Consider a series RC circuit with resistor $ R $ and capacitor $ C $, charged to initial voltage $ V_0 = 1 $ V, then discharged (switch opens at $ t=0 $).\n",
        "\n",
        "By KVL: Voltage drop across R + C = 0 (no source), so:\n",
        "\\[\n",
        "\\frac{dV}{dt} = -\\frac{V}{RC} = -\\frac{V}{\\tau}\n",
        "\\]\n",
        "- Time domain: $ t \\in [0, 5\\tau] $, where $ \\tau = RC = 1 $ s (normalize for simplicity).\n",
        "- Initial condition (IC): $ V(0) = 1 $.\n",
        "- Exact solution: $ V(t) = e^{-t/\\tau} $ (exponential decay).\n",
        "\n",
        "We'll use:\n",
        "- **50 IC points** (just t=0, but duplicated for stability; treat as \"data\").\n",
        "- **5,000 collocation points** in time for ODE residual.\n",
        "\n",
        "This teaches ODE solvingâ€”PINNs shine for stiff/nonlinear ODEs, but works great here.\n",
        "\n",
        "### Step 1: Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e65cbb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Problem parameters\n",
        "tau = 1.0  # RC time constant\n",
        "t_max = 5.0  # Simulate up to 5 tau\n",
        "N_u = 50  # IC points (oversampled at t=0)\n",
        "N_f = 5000  # Collocation points\n",
        "V0 = 1.0  # Initial voltage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 2: Neural Network\n",
        "Input: $ t $ (1D). Output: $ V(t) $. 3 hidden layers of 20 neurons (simpler for ODE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854a851f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PINN_ODE(nn.Module):\n",
        "    def __init__(self, layers=[1] + [20]*3 + [1]):\n",
        "        super(PINN_ODE, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(layers) - 1):\n",
        "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
        "    \n",
        "    def forward(self, t):\n",
        "        inp = t  # Single input\n",
        "        for i, layer in enumerate(self.layers[:-1]):\n",
        "            inp = torch.tanh(layer(inp))\n",
        "        V = self.layers[-1](inp)\n",
        "        return V"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 3: Generate Training Data\n",
        "- IC: Multiple points at t=0 with V=1.\n",
        "- Collocation: Uniform random t in [0, t_max]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004b589e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# IC points (all at t=0)\n",
        "t_u = torch.zeros((N_u, 1), requires_grad=True).to(device)\n",
        "V_u = torch.full_like(t_u, V0)\n",
        "\n",
        "# Collocation points\n",
        "t_f = torch.rand((N_f, 1), dtype=torch.float32) * t_max\n",
        "t_f = t_f.requires_grad_(True).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 4: Physics Loss\n",
        "ODE residual: $ \\frac{dV}{dt} + \\frac{V}{\\tau} = 0 $."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acf00f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def physics_loss(model, t_f, tau):\n",
        "    V_pred = model(t_f)\n",
        "    dV_dt = torch.autograd.grad(V_pred, t_f, grad_outputs=torch.ones_like(V_pred),\n",
        "                                create_graph=True, retain_graph=True)[0]\n",
        "    f = dV_dt + V_pred / tau\n",
        "    return torch.mean(f**2)\n",
        "\n",
        "def total_loss(model, t_u, V_u, t_f, tau, lambda_f=1.0):\n",
        "    V_pred_u = model(t_u)\n",
        "    loss_u = torch.mean((V_pred_u - V_u)**2)\n",
        "    loss_f = physics_loss(model, t_f, tau)\n",
        "    return loss_u + lambda_f * loss_f"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 5: Training\n",
        "Adam for 2000 epochs, then LBFGS for 500."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f5fd991",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ode = PINN_ODE().to(device)\n",
        "optimizer_adam = torch.optim.Adam(model_ode.parameters(), lr=1e-3)\n",
        "optimizer_lbfgs = torch.optim.LBFGS(model_ode.parameters(), lr=1.0, max_iter=50)\n",
        "\n",
        "def closure_ode():\n",
        "    optimizer_lbfgs.zero_grad()\n",
        "    loss = total_loss(model_ode, t_u, V_u, t_f, tau)\n",
        "    loss.backward(retain_graph=True)\n",
        "    return loss\n",
        "\n",
        "print(\"Training RC Circuit PINN...\")\n",
        "for epoch in range(2000):\n",
        "    optimizer_adam.zero_grad()\n",
        "    loss = total_loss(model_ode, t_u, V_u, t_f, tau)\n",
        "    loss.backward()\n",
        "    optimizer_adam.step()\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer_lbfgs.step(closure_ode)\n",
        "    loss = closure_ode()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"LBFGS {epoch}, Loss: {loss.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 6: Evaluation and Plot\n",
        "Compare to exact solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06291b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine grid\n",
        "t_test = torch.linspace(0, t_max, 100).reshape(-1, 1).to(device)\n",
        "with torch.no_grad():\n",
        "    V_pred = model_ode(t_test).cpu()\n",
        "\n",
        "# Exact\n",
        "t_exact = t_test.cpu().squeeze()\n",
        "V_exact = np.exp(-t_exact / tau)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(t_exact, V_exact, 'b-', label='Exact: $V(t) = e^{-t/\\\\tau}$')\n",
        "plt.plot(t_exact, V_pred.squeeze(), 'r--', label='PINN Prediction')\n",
        "plt.xlabel('Time t (s)')\n",
        "plt.ylabel('Voltage V(t) (V)')\n",
        "plt.title('RC Circuit: Capacitor Voltage Decay')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "**Expected Output**: The PINN curve should hug the exponential decay closely (error < 1e-3). Discuss: How does this enforce Kirchhoff? (Residual minimizes current imbalance.)\n",
        "\n",
        "## Example 2: 1D Heat Diffusion Equation\n",
        "### Problem Setup\n",
        "Heat conduction in a 1D rod (length L=1 m), insulated ends (zero flux BCs).\n",
        "\n",
        "PDE (Fourier's law):\n",
        "\\[\n",
        "\\frac{\\partial T}{\\partial t} = \\alpha \\frac{\\partial^2 T}{\\partial x^2}\n",
        "\\]\n",
        "- Domain: $ x \\in [0, 1] $, $ t \\in [0, 0.5] $.\n",
        "- Initial condition (IC): $ T(x,0) = \\sin(\\pi x) $ (hot in middle).\n",
        "- Boundary conditions (BCs): $ \\frac{\\partial T}{\\partial x}(0,t) = \\frac{\\partial T}{\\partial x}(1,t) = 0 $ (Neumann; no heat loss).\n",
        "- Diffusivity: $ \\alpha = 0.1 $ (slow diffusion for visibility).\n",
        "\n",
        "Exact solution involves Fourier series, but PINNs approximate it mesh-free.\n",
        "\n",
        "Use:\n",
        "- **100 points** for IC/BCs.\n",
        "- **10,000 collocation points** for PDE.\n",
        "\n",
        "This builds on Burgers' but linearâ€”easier convergence.\n",
        "\n",
        "### Step 1: Imports and Setup\n",
        "(Same as before; add:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16eb7e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha = 0.1  # Thermal diffusivity\n",
        "x_min, x_max = 0.0, 1.0\n",
        "t_max_heat = 0.5\n",
        "N_u_heat = 100\n",
        "N_f_heat = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 2: Neural Network\n",
        "Same as Burgers': Input (x,t), 4x50 tanh layers.\n",
        "\n",
        "(Reuse `PINN` class from original tutorial.)\n",
        "\n",
        "### Step 3: Generate Data\n",
        "- IC: t=0, x uniform.\n",
        "- BCs: x=0 and x=1, t uniform (but enforce flux=0 via derivative in loss).\n",
        "- Collocation: Random (x,t).\n",
        "\n",
        "For Neumann BCs, sample points on boundaries and add loss for dT/dx=0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b16866",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_heat_data(N_u, N_f, x_min, x_max, t_max, alpha):\n",
        "    # IC points\n",
        "    N_init = N_u // 3\n",
        "    x_init = torch.linspace(x_min, x_max, N_init).reshape(-1, 1).requires_grad_(True)\n",
        "    t_init = torch.zeros_like(x_init).requires_grad_(True)\n",
        "    T_init = torch.sin(np.pi * x_init)\n",
        "    \n",
        "    # Left BC: x=0, t uniform (for dT/dx=0)\n",
        "    N_left = N_u // 3\n",
        "    x_left = torch.zeros((N_left, 1), requires_grad=True).to(device)\n",
        "    t_left = torch.rand((N_left, 1)) * t_max\n",
        "    t_left.requires_grad_(True).to(device)\n",
        "    \n",
        "    # Right BC: x=1, t uniform\n",
        "    N_right = N_u - N_init - N_left\n",
        "    x_right = torch.ones((N_right, 1), requires_grad=True).to(device)\n",
        "    t_right = torch.rand((N_right, 1)) * t_max\n",
        "    t_right.requires_grad_(True).to(device)\n",
        "    \n",
        "    # Concat IC + boundaries (no T values for BCs; enforced via derivative)\n",
        "    x_u = torch.cat([x_init, x_left, x_right], dim=0).to(device)\n",
        "    t_u = torch.cat([t_init, t_left, t_right], dim=0).to(device)\n",
        "    T_u = torch.cat([T_init, torch.zeros((N_u - N_init, 1))], dim=0).to(device)  # Dummy for BCs; override in loss\n",
        "    \n",
        "    # Collocation\n",
        "    x_f = torch.rand((N_f, 1)) * (x_max - x_min) + x_min\n",
        "    t_f = torch.rand((N_f, 1)) * t_max\n",
        "    x_f.requires_grad_(True).to(device)\n",
        "    t_f.requires_grad_(True).to(device)\n",
        "    \n",
        "    return x_u, t_u, T_u, x_f, t_f\n",
        "\n",
        "x_u_h, t_u_h, T_u_h, x_f_h, t_f_h = generate_heat_data(N_u_heat, N_f_heat, x_min, x_max, t_max_heat, alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 4: Physics Loss\n",
        "PDE: $ T_t - \\alpha T_{xx} = 0 $.\n",
        "\n",
        "For BCs: Add MSE on $ T_x $ at boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390dec6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def heat_physics_loss(model, x_f, t_f, alpha, x_u, t_u):\n",
        "    # PDE residual\n",
        "    T_pred = model(x_f, t_f)\n",
        "    T_x = torch.autograd.grad(T_pred, x_f, torch.ones_like(T_pred), create_graph=True, retain_graph=True)[0]\n",
        "    T_t = torch.autograd.grad(T_pred, t_f, torch.ones_like(T_pred), create_graph=True, retain_graph=True)[0]\n",
        "    T_xx = torch.autograd.grad(T_x, x_f, torch.ones_like(T_x), create_graph=True, retain_graph=True)[0]\n",
        "    f_pde = T_t - alpha * T_xx\n",
        "    loss_pde = torch.mean(f_pde**2)\n",
        "    \n",
        "    # Neumann BC loss: dT/dx = 0 at x=0 and x=1\n",
        "    # Left\n",
        "    T_left = model(x_u[:N_u_heat//3 + N_init//3], t_u[:N_u_heat//3 + N_init//3])  # Wait, better slice properly\n",
        "    # Actually, separate BC points\n",
        "    idx_left = slice(N_init, N_init + N_left)\n",
        "    idx_right = slice(N_init + N_left, None)\n",
        "    T_x_left = torch.autograd.grad(model(x_u[idx_left], t_u[idx_left]), x_u[idx_left], \n",
        "                                   torch.ones_like(model(x_u[idx_left], t_u[idx_left])), \n",
        "                                   create_graph=True)[0]\n",
        "    T_x_right = torch.autograd.grad(model(x_u[idx_right], t_u[idx_right]), x_u[idx_right], \n",
        "                                    torch.ones_like(model(x_u[idx_right], t_u[idx_right])), \n",
        "                                    create_graph=True)[0]\n",
        "    loss_bc = torch.mean(T_x_left**2) + torch.mean(T_x_right**2)\n",
        "    \n",
        "    return loss_pde + loss_bc\n",
        "\n",
        "def heat_total_loss(model, x_u, t_u, T_u, x_f, t_f, alpha):\n",
        "    # IC loss (only for init points)\n",
        "    idx_init = slice(0, N_u_heat // 3)\n",
        "    T_pred_init = model(x_u[idx_init], t_u[idx_init])\n",
        "    loss_ic = torch.mean((T_pred_init - T_u[idx_init])**2)\n",
        "    \n",
        "    # Physics (PDE + BC)\n",
        "    loss_phys = heat_physics_loss(model, x_f, t_f, alpha, x_u, t_u)\n",
        "    \n",
        "    return loss_ic + loss_phys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "Wait, small fix: In generate, N_init = N_u//3, etc. For simplicity, in loss, we can compute IC separately.\n",
        "\n",
        "To make it clean, adjust:\n",
        "\n",
        "In total_loss:\n",
        "- loss_u = MSE only on IC points.\n",
        "- loss_f = PDE on collocation + BC derivative on boundary points.\n",
        "\n",
        "Yes.\n",
        "\n",
        "### Step 5: Training\n",
        "Similar loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e512b81",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_heat = PINN().to(device)  # From original\n",
        "optimizer_adam_h = torch.optim.Adam(model_heat.parameters(), lr=1e-3)\n",
        "optimizer_lbfgs_h = torch.optim.LBFGS(model_heat.parameters(), lr=1.0, max_iter=50)\n",
        "\n",
        "def closure_heat():\n",
        "    optimizer_lbfgs_h.zero_grad()\n",
        "    loss = heat_total_loss(model_heat, x_u_h, t_u_h, T_u_h, x_f_h, t_f_h, alpha)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "# Training (adjust epochs as needed)\n",
        "for epoch in range(3000):\n",
        "    optimizer_adam_h.zero_grad()\n",
        "    loss = heat_total_loss(model_heat, x_u_h, t_u_h, T_u_h, x_f_h, t_f_h, alpha)\n",
        "    loss.backward()\n",
        "    optimizer_adam_h.step()\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Heat Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer_lbfgs_h.step(closure_heat)\n",
        "    loss = closure_heat()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Heat LBFGS {epoch}, Loss: {loss.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "### Step 6: Evaluation and Plot\n",
        "Contour of T(x,t)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d61e409",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine grid\n",
        "x_test_h = torch.linspace(x_min, x_max, 100).reshape(-1, 1).to(device)\n",
        "t_test_h = torch.linspace(0, t_max_heat, 50).reshape(-1, 1).to(device)\n",
        "X_h, T_h = torch.meshgrid(x_test_h.squeeze(), t_test_h.squeeze(), indexing='xy')\n",
        "\n",
        "with torch.no_grad():\n",
        "    Temp_pred = model_heat(X_h.flatten()[:, None], T_h.flatten()[:, None]).reshape(X_h.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "contour = plt.contourf(T_h.cpu(), X_h.cpu(), Temp_pred.cpu(), levels=50, cmap='hot')\n",
        "plt.xlabel('Time t')\n",
        "plt.ylabel('Position x')\n",
        "plt.title(\"PINN Solution: Temperature T(x,t) in 1D Rod\")\n",
        "plt.colorbar(contour)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# IC comparison\n",
        "idx_init_h = slice(0, N_u_heat // 3)\n",
        "T_init_pred = model_heat(x_u_h[idx_init_h], t_u_h[idx_init_h]).detach().cpu()\n",
        "plt.figure(figsize=(8, 4))\n",
        "x_init_plot = x_u_h[idx_init_h].cpu().squeeze()\n",
        "plt.plot(x_init_plot, torch.sin(np.pi * x_init_plot.cpu()), 'b-', label='True IC')\n",
        "plt.plot(x_init_plot, T_init_pred.squeeze(), 'r--', label='PINN IC')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('T(x,0)')\n",
        "plt.title('Initial Temperature Profile')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a778c4d4",
      "metadata": {},
      "source": [
        "**Expected Output**: Heat diffuses from center, flattening over time. Contours smooth; error small.\n",
        "\n",
        "## Wrapping Up\n",
        "These examples bridge familiar physics to ML: RC shows ODEs (circuits class), heat PDEs (thermo class). Encourage students to:\n",
        "- Modify ICs (e.g., step function for heat).\n",
        "- Add noise to \"data\" for inverse problems (estimate Î± from measurements).\n",
        "- Compare runtime to finite differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1981fb78",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character 'â€”' (U+2014) (1666217392.py, line 3)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mAbsolutely! Great ideaâ€”students often find electrical circuits and heat transfer more intuitive than fluid dynamics. We'll adapt the PINN framework to two classic problems they're likely familiar with from intro physics/engineering courses:\u001b[39m\n                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character 'â€”' (U+2014)\n"
          ]
        }
      ],
      "source": [
        "# Physics-Informed Neural Networks (PINNs) in PyTorch: Familiar Examples Tutorial\n",
        "\n",
        "Absolutely! Great ideaâ€”students often find electrical circuits and heat transfer more intuitive than fluid dynamics. We'll adapt the PINN framework to two classic problems they're likely familiar with from intro physics/engineering courses:\n",
        "\n",
        "1. **Kirchhoff's Voltage Law (KVL) for an RC Circuit**: This leads to a simple **ordinary differential equation (ODE)** for the capacitor voltage decay. It's a 1D time-domain problem.\n",
        "2. **1D Heat Diffusion Equation**: The classic **heat equation**, a linear PDE modeling temperature evolution in a rod.\n",
        "\n",
        "These showcase PINNs for both ODEs (easier entry) and PDEs. We'll keep the structure similar to the Burgers' tutorial: PyTorch-based, with automatic differentiation, Adam + LBFGS optimization, and visualizations. Each section is self-containedâ€”run them independently in a Jupyter notebook.\n",
        "\n",
        "Assumptions: Students know basic PyTorch, ODEs/PDEs, and circuits/heat transfer. Runtime: ~1-2 minutes per example on CPU.\n",
        "\n",
        "## Quick PINN Recap\n",
        "PINNs approximate solutions $ u(\\mathbf{x}) $ (e.g., voltage or temperature) with a neural net, trained to minimize:\n",
        "- **Data loss**: Matches initial/boundary conditions.\n",
        "- **Physics loss**: PDE/ODE residual â‰ˆ 0 at random \"collocation\" points.\n",
        "\n",
        "## Example 1: RC Circuit ODE (Kirchhoff's Law)\n",
        "### Problem Setup\n",
        "Consider a series RC circuit with resistor $ R $ and capacitor $ C $, charged to initial voltage $ V_0 = 1 $ V, then discharged (switch opens at $ t=0 $).\n",
        "\n",
        "By KVL: Voltage drop across R + C = 0 (no source), so:\n",
        "\\[\n",
        "\\frac{dV}{dt} = -\\frac{V}{RC} = -\\frac{V}{\\tau}\n",
        "\\]\n",
        "- Time domain: $ t \\in [0, 5\\tau] $, where $ \\tau = RC = 1 $ s (normalize for simplicity).\n",
        "- Initial condition (IC): $ V(0) = 1 $.\n",
        "- Exact solution: $ V(t) = e^{-t/\\tau} $ (exponential decay).\n",
        "\n",
        "We'll use:\n",
        "- **50 IC points** (just t=0, but duplicated for stability; treat as \"data\").\n",
        "- **5,000 collocation points** in time for ODE residual.\n",
        "\n",
        "This teaches ODE solvingâ€”PINNs shine for stiff/nonlinear ODEs, but works great here.\n",
        "\n",
        "### Step 1: Imports and Setup\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Problem parameters\n",
        "tau = 1.0  # RC time constant\n",
        "t_max = 5.0  # Simulate up to 5 tau\n",
        "N_u = 50  # IC points (oversampled at t=0)\n",
        "N_f = 5000  # Collocation points\n",
        "V0 = 1.0  # Initial voltage\n",
        "```\n",
        "\n",
        "### Step 2: Neural Network\n",
        "Input: $ t $ (1D). Output: $ V(t) $. 3 hidden layers of 20 neurons (simpler for ODE).\n",
        "\n",
        "```python\n",
        "class PINN_ODE(nn.Module):\n",
        "    def __init__(self, layers=[1] + [20]*3 + [1]):\n",
        "        super(PINN_ODE, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(layers) - 1):\n",
        "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
        "    \n",
        "    def forward(self, t):\n",
        "        inp = t  # Single input\n",
        "        for i, layer in enumerate(self.layers[:-1]):\n",
        "            inp = torch.tanh(layer(inp))\n",
        "        V = self.layers[-1](inp)\n",
        "        return V\n",
        "```\n",
        "\n",
        "### Step 3: Generate Training Data\n",
        "- IC: Multiple points at t=0 with V=1.\n",
        "- Collocation: Uniform random t in [0, t_max].\n",
        "\n",
        "```python\n",
        "# IC points (all at t=0)\n",
        "t_u = torch.zeros((N_u, 1), requires_grad=True).to(device)\n",
        "V_u = torch.full_like(t_u, V0)\n",
        "\n",
        "# Collocation points\n",
        "t_f = torch.rand((N_f, 1), dtype=torch.float32) * t_max\n",
        "t_f = t_f.requires_grad_(True).to(device)\n",
        "```\n",
        "\n",
        "### Step 4: Physics Loss\n",
        "ODE residual: $ \\frac{dV}{dt} + \\frac{V}{\\tau} = 0 $.\n",
        "\n",
        "```python\n",
        "def physics_loss(model, t_f, tau):\n",
        "    V_pred = model(t_f)\n",
        "    dV_dt = torch.autograd.grad(V_pred, t_f, grad_outputs=torch.ones_like(V_pred),\n",
        "                                create_graph=True, retain_graph=True)[0]\n",
        "    f = dV_dt + V_pred / tau\n",
        "    return torch.mean(f**2)\n",
        "\n",
        "def total_loss(model, t_u, V_u, t_f, tau, lambda_f=1.0):\n",
        "    V_pred_u = model(t_u)\n",
        "    loss_u = torch.mean((V_pred_u - V_u)**2)\n",
        "    loss_f = physics_loss(model, t_f, tau)\n",
        "    return loss_u + lambda_f * loss_f\n",
        "```\n",
        "\n",
        "### Step 5: Training\n",
        "Adam for 2000 epochs, then LBFGS for 500.\n",
        "\n",
        "```python\n",
        "model_ode = PINN_ODE().to(device)\n",
        "optimizer_adam = torch.optim.Adam(model_ode.parameters(), lr=1e-3)\n",
        "optimizer_lbfgs = torch.optim.LBFGS(model_ode.parameters(), lr=1.0, max_iter=50)\n",
        "\n",
        "def closure_ode():\n",
        "    optimizer_lbfgs.zero_grad()\n",
        "    loss = total_loss(model_ode, t_u, V_u, t_f, tau)\n",
        "    loss.backward(retain_graph=True)\n",
        "    return loss\n",
        "\n",
        "print(\"Training RC Circuit PINN...\")\n",
        "for epoch in range(2000):\n",
        "    optimizer_adam.zero_grad()\n",
        "    loss = total_loss(model_ode, t_u, V_u, t_f, tau)\n",
        "    loss.backward()\n",
        "    optimizer_adam.step()\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer_lbfgs.step(closure_ode)\n",
        "    loss = closure_ode()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"LBFGS {epoch}, Loss: {loss.item():.6f}\")\n",
        "```\n",
        "\n",
        "### Step 6: Evaluation and Plot\n",
        "Compare to exact solution.\n",
        "\n",
        "```python\n",
        "# Fine grid\n",
        "t_test = torch.linspace(0, t_max, 100).reshape(-1, 1).to(device)\n",
        "with torch.no_grad():\n",
        "    V_pred = model_ode(t_test).cpu()\n",
        "\n",
        "# Exact\n",
        "t_exact = t_test.cpu().squeeze()\n",
        "V_exact = np.exp(-t_exact / tau)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(t_exact, V_exact, 'b-', label='Exact: $V(t) = e^{-t/\\\\tau}$')\n",
        "plt.plot(t_exact, V_pred.squeeze(), 'r--', label='PINN Prediction')\n",
        "plt.xlabel('Time t (s)')\n",
        "plt.ylabel('Voltage V(t) (V)')\n",
        "plt.title('RC Circuit: Capacitor Voltage Decay')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Expected Output**: The PINN curve should hug the exponential decay closely (error < 1e-3). Discuss: How does this enforce Kirchhoff? (Residual minimizes current imbalance.)\n",
        "\n",
        "## Example 2: 1D Heat Diffusion Equation\n",
        "### Problem Setup\n",
        "Heat conduction in a 1D rod (length L=1 m), insulated ends (zero flux BCs).\n",
        "\n",
        "PDE (Fourier's law):\n",
        "\\[\n",
        "\\frac{\\partial T}{\\partial t} = \\alpha \\frac{\\partial^2 T}{\\partial x^2}\n",
        "\\]\n",
        "- Domain: $ x \\in [0, 1] $, $ t \\in [0, 0.5] $.\n",
        "- Initial condition (IC): $ T(x,0) = \\sin(\\pi x) $ (hot in middle).\n",
        "- Boundary conditions (BCs): $ \\frac{\\partial T}{\\partial x}(0,t) = \\frac{\\partial T}{\\partial x}(1,t) = 0 $ (Neumann; no heat loss).\n",
        "- Diffusivity: $ \\alpha = 0.1 $ (slow diffusion for visibility).\n",
        "\n",
        "Exact solution involves Fourier series, but PINNs approximate it mesh-free.\n",
        "\n",
        "Use:\n",
        "- **100 points** for IC/BCs.\n",
        "- **10,000 collocation points** for PDE.\n",
        "\n",
        "This builds on Burgers' but linearâ€”easier convergence.\n",
        "\n",
        "### Step 1: Imports and Setup\n",
        "(Same as before; add:)\n",
        "```python\n",
        "alpha = 0.1  # Thermal diffusivity\n",
        "x_min, x_max = 0.0, 1.0\n",
        "t_max_heat = 0.5\n",
        "N_u_heat = 100\n",
        "N_f_heat = 10000\n",
        "```\n",
        "\n",
        "### Step 2: Neural Network\n",
        "Same as Burgers': Input (x,t), 4x50 tanh layers.\n",
        "\n",
        "(Reuse `PINN` class from original tutorial.)\n",
        "\n",
        "### Step 3: Generate Data\n",
        "- IC: t=0, x uniform.\n",
        "- BCs: x=0 and x=1, t uniform (but enforce flux=0 via derivative in loss).\n",
        "- Collocation: Random (x,t).\n",
        "\n",
        "For Neumann BCs, sample points on boundaries and add loss for dT/dx=0.\n",
        "\n",
        "```python\n",
        "def generate_heat_data(N_u, N_f, x_min, x_max, t_max, alpha):\n",
        "    # IC points\n",
        "    N_init = N_u // 3\n",
        "    x_init = torch.linspace(x_min, x_max, N_init).reshape(-1, 1).requires_grad_(True)\n",
        "    t_init = torch.zeros_like(x_init).requires_grad_(True)\n",
        "    T_init = torch.sin(np.pi * x_init)\n",
        "    \n",
        "    # Left BC: x=0, t uniform (for dT/dx=0)\n",
        "    N_left = N_u // 3\n",
        "    x_left = torch.zeros((N_left, 1), requires_grad=True).to(device)\n",
        "    t_left = torch.rand((N_left, 1)) * t_max\n",
        "    t_left.requires_grad_(True).to(device)\n",
        "    \n",
        "    # Right BC: x=1, t uniform\n",
        "    N_right = N_u - N_init - N_left\n",
        "    x_right = torch.ones((N_right, 1), requires_grad=True).to(device)\n",
        "    t_right = torch.rand((N_right, 1)) * t_max\n",
        "    t_right.requires_grad_(True).to(device)\n",
        "    \n",
        "    # Concat IC + boundaries (no T values for BCs; enforced via derivative)\n",
        "    x_u = torch.cat([x_init, x_left, x_right], dim=0).to(device)\n",
        "    t_u = torch.cat([t_init, t_left, t_right], dim=0).to(device)\n",
        "    T_u = torch.cat([T_init, torch.zeros((N_u - N_init, 1))], dim=0).to(device)  # Dummy for BCs; override in loss\n",
        "    \n",
        "    # Collocation\n",
        "    x_f = torch.rand((N_f, 1)) * (x_max - x_min) + x_min\n",
        "    t_f = torch.rand((N_f, 1)) * t_max\n",
        "    x_f.requires_grad_(True).to(device)\n",
        "    t_f.requires_grad_(True).to(device)\n",
        "    \n",
        "    return x_u, t_u, T_u, x_f, t_f\n",
        "\n",
        "x_u_h, t_u_h, T_u_h, x_f_h, t_f_h = generate_heat_data(N_u_heat, N_f_heat, x_min, x_max, t_max_heat, alpha)\n",
        "```\n",
        "\n",
        "### Step 4: Physics Loss\n",
        "PDE: $ T_t - \\alpha T_{xx} = 0 $.\n",
        "\n",
        "For BCs: Add MSE on $ T_x $ at boundaries.\n",
        "\n",
        "```python\n",
        "def heat_physics_loss(model, x_f, t_f, alpha, x_u, t_u):\n",
        "    # PDE residual\n",
        "    T_pred = model(x_f, t_f)\n",
        "    T_x = torch.autograd.grad(T_pred, x_f, torch.ones_like(T_pred), create_graph=True, retain_graph=True)[0]\n",
        "    T_t = torch.autograd.grad(T_pred, t_f, torch.ones_like(T_pred), create_graph=True, retain_graph=True)[0]\n",
        "    T_xx = torch.autograd.grad(T_x, x_f, torch.ones_like(T_x), create_graph=True, retain_graph=True)[0]\n",
        "    f_pde = T_t - alpha * T_xx\n",
        "    loss_pde = torch.mean(f_pde**2)\n",
        "    \n",
        "    # Neumann BC loss: dT/dx = 0 at x=0 and x=1\n",
        "    # Left\n",
        "    T_left = model(x_u[:N_u_heat//3 + N_init//3], t_u[:N_u_heat//3 + N_init//3])  # Wait, better slice properly\n",
        "    # Actually, separate BC points\n",
        "    idx_left = slice(N_init, N_init + N_left)\n",
        "    idx_right = slice(N_init + N_left, None)\n",
        "    T_x_left = torch.autograd.grad(model(x_u[idx_left], t_u[idx_left]), x_u[idx_left], \n",
        "                                   torch.ones_like(model(x_u[idx_left], t_u[idx_left])), \n",
        "                                   create_graph=True)[0]\n",
        "    T_x_right = torch.autograd.grad(model(x_u[idx_right], t_u[idx_right]), x_u[idx_right], \n",
        "                                    torch.ones_like(model(x_u[idx_right], t_u[idx_right])), \n",
        "                                    create_graph=True)[0]\n",
        "    loss_bc = torch.mean(T_x_left**2) + torch.mean(T_x_right**2)\n",
        "    \n",
        "    return loss_pde + loss_bc\n",
        "\n",
        "def heat_total_loss(model, x_u, t_u, T_u, x_f, t_f, alpha):\n",
        "    # IC loss (only for init points)\n",
        "    idx_init = slice(0, N_u_heat // 3)\n",
        "    T_pred_init = model(x_u[idx_init], t_u[idx_init])\n",
        "    loss_ic = torch.mean((T_pred_init - T_u[idx_init])**2)\n",
        "    \n",
        "    # Physics (PDE + BC)\n",
        "    loss_phys = heat_physics_loss(model, x_f, t_f, alpha, x_u, t_u)\n",
        "    \n",
        "    return loss_ic + loss_phys\n",
        "```\n",
        "\n",
        "Wait, small fix: In generate, N_init = N_u//3, etc. For simplicity, in loss, we can compute IC separately.\n",
        "\n",
        "To make it clean, adjust:\n",
        "\n",
        "In total_loss:\n",
        "- loss_u = MSE only on IC points.\n",
        "- loss_f = PDE on collocation + BC derivative on boundary points.\n",
        "\n",
        "Yes.\n",
        "\n",
        "### Step 5: Training\n",
        "Similar loop.\n",
        "\n",
        "```python\n",
        "model_heat = PINN().to(device)  # From original\n",
        "optimizer_adam_h = torch.optim.Adam(model_heat.parameters(), lr=1e-3)\n",
        "optimizer_lbfgs_h = torch.optim.LBFGS(model_heat.parameters(), lr=1.0, max_iter=50)\n",
        "\n",
        "def closure_heat():\n",
        "    optimizer_lbfgs_h.zero_grad()\n",
        "    loss = heat_total_loss(model_heat, x_u_h, t_u_h, T_u_h, x_f_h, t_f_h, alpha)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "# Training (adjust epochs as needed)\n",
        "for epoch in range(3000):\n",
        "    optimizer_adam_h.zero_grad()\n",
        "    loss = heat_total_loss(model_heat, x_u_h, t_u_h, T_u_h, x_f_h, t_f_h, alpha)\n",
        "    loss.backward()\n",
        "    optimizer_adam_h.step()\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Heat Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer_lbfgs_h.step(closure_heat)\n",
        "    loss = closure_heat()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Heat LBFGS {epoch}, Loss: {loss.item():.6f}\")\n",
        "```\n",
        "\n",
        "### Step 6: Evaluation and Plot\n",
        "Contour of T(x,t).\n",
        "\n",
        "```python\n",
        "# Fine grid\n",
        "x_test_h = torch.linspace(x_min, x_max, 100).reshape(-1, 1).to(device)\n",
        "t_test_h = torch.linspace(0, t_max_heat, 50).reshape(-1, 1).to(device)\n",
        "X_h, T_h = torch.meshgrid(x_test_h.squeeze(), t_test_h.squeeze(), indexing='xy')\n",
        "\n",
        "with torch.no_grad():\n",
        "    Temp_pred = model_heat(X_h.flatten()[:, None], T_h.flatten()[:, None]).reshape(X_h.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "contour = plt.contourf(T_h.cpu(), X_h.cpu(), Temp_pred.cpu(), levels=50, cmap='hot')\n",
        "plt.xlabel('Time t')\n",
        "plt.ylabel('Position x')\n",
        "plt.title(\"PINN Solution: Temperature T(x,t) in 1D Rod\")\n",
        "plt.colorbar(contour)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# IC comparison\n",
        "idx_init_h = slice(0, N_u_heat // 3)\n",
        "T_init_pred = model_heat(x_u_h[idx_init_h], t_u_h[idx_init_h]).detach().cpu()\n",
        "plt.figure(figsize=(8, 4))\n",
        "x_init_plot = x_u_h[idx_init_h].cpu().squeeze()\n",
        "plt.plot(x_init_plot, torch.sin(np.pi * x_init_plot.cpu()), 'b-', label='True IC')\n",
        "plt.plot(x_init_plot, T_init_pred.squeeze(), 'r--', label='PINN IC')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('T(x,0)')\n",
        "plt.title('Initial Temperature Profile')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**Expected Output**: Heat diffuses from center, flattening over time. Contours smooth; error small.\n",
        "\n",
        "## Wrapping Up\n",
        "These examples bridge familiar physics to ML: RC shows ODEs (circuits class), heat PDEs (thermo class). Encourage students to:\n",
        "- Modify ICs (e.g., step function for heat).\n",
        "- Add noise to \"data\" for inverse problems (estimate Î± from measurements).\n",
        "- Compare runtime to finite differences.\n",
        "\n",
        "Full code in one notebook? Paste sections together. Questions? Let's tweak! ðŸ”§"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
