{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "torch.Size([50, 840, 64]) torch.Size([1, 840, 64]) torch.Size([1, 840, 64])\n",
      "output tensor([[[-0.0274, -0.0183, -0.0058,  ..., -0.0182, -0.0375,  0.0215],\n",
      "         [-0.0303, -0.0084, -0.0122,  ..., -0.0176, -0.0338,  0.0237],\n",
      "         [-0.0189,  0.0017, -0.0298,  ..., -0.0125, -0.0234,  0.0352],\n",
      "         ...,\n",
      "         [-0.0655,  0.0309, -0.0562,  ..., -0.0098, -0.0408,  0.0422],\n",
      "         [-0.0681,  0.0344, -0.0649,  ..., -0.0051, -0.0402,  0.0428],\n",
      "         [-0.0752,  0.0401, -0.0596,  ...,  0.0065, -0.0469,  0.0426]],\n",
      "\n",
      "        [[-0.0464, -0.0226, -0.0143,  ..., -0.0255, -0.0580,  0.0309],\n",
      "         [-0.0503, -0.0094, -0.0247,  ..., -0.0229, -0.0529,  0.0336],\n",
      "         [-0.0330,  0.0035, -0.0515,  ..., -0.0161, -0.0367,  0.0515],\n",
      "         ...,\n",
      "         [-0.0914,  0.0404, -0.0925,  ..., -0.0049, -0.0617,  0.0607],\n",
      "         [-0.0938,  0.0433, -0.1048,  ...,  0.0025, -0.0604,  0.0613],\n",
      "         [-0.1022,  0.0512, -0.0976,  ...,  0.0184, -0.0689,  0.0611]],\n",
      "\n",
      "        [[-0.0603, -0.0199, -0.0245,  ..., -0.0268, -0.0700,  0.0359],\n",
      "         [-0.0642, -0.0058, -0.0374,  ..., -0.0222, -0.0641,  0.0386],\n",
      "         [-0.0435,  0.0075, -0.0687,  ..., -0.0154, -0.0450,  0.0599],\n",
      "         ...,\n",
      "         [-0.1020,  0.0448, -0.1150,  ...,  0.0031, -0.0717,  0.0693],\n",
      "         [-0.1035,  0.0463, -0.1280,  ...,  0.0115, -0.0698,  0.0701],\n",
      "         [-0.1114,  0.0543, -0.1204,  ...,  0.0274, -0.0781,  0.0696]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0382, -0.0827,  0.1087,  ..., -0.0684, -0.0269,  0.0505],\n",
      "         [ 0.0368, -0.0854,  0.1161,  ..., -0.0695, -0.0297,  0.0464],\n",
      "         [ 0.0265, -0.0882,  0.1256,  ..., -0.0709, -0.0388,  0.0334],\n",
      "         ...,\n",
      "         [ 0.0336, -0.0816,  0.1261,  ..., -0.0753, -0.0264,  0.0362],\n",
      "         [ 0.0313, -0.0791,  0.1190,  ..., -0.0758, -0.0246,  0.0379],\n",
      "         [ 0.0276, -0.0729,  0.1229,  ..., -0.0686, -0.0315,  0.0405]],\n",
      "\n",
      "        [[ 0.0400, -0.0843,  0.1150,  ..., -0.0695, -0.0259,  0.0481],\n",
      "         [ 0.0386, -0.0862,  0.1212,  ..., -0.0705, -0.0282,  0.0439],\n",
      "         [ 0.0301, -0.0880,  0.1287,  ..., -0.0715, -0.0352,  0.0333],\n",
      "         ...,\n",
      "         [ 0.0306, -0.0791,  0.1225,  ..., -0.0764, -0.0271,  0.0374],\n",
      "         [ 0.0281, -0.0767,  0.1136,  ..., -0.0765, -0.0250,  0.0396],\n",
      "         [ 0.0232, -0.0695,  0.1183,  ..., -0.0675, -0.0338,  0.0422]],\n",
      "\n",
      "        [[ 0.0411, -0.0855,  0.1202,  ..., -0.0705, -0.0252,  0.0457],\n",
      "         [ 0.0398, -0.0865,  0.1252,  ..., -0.0714, -0.0270,  0.0415],\n",
      "         [ 0.0330, -0.0873,  0.1307,  ..., -0.0720, -0.0320,  0.0334],\n",
      "         ...,\n",
      "         [ 0.0270, -0.0762,  0.1179,  ..., -0.0772, -0.0282,  0.0388],\n",
      "         [ 0.0242, -0.0740,  0.1071,  ..., -0.0770, -0.0259,  0.0415],\n",
      "         [ 0.0182, -0.0658,  0.1128,  ..., -0.0661, -0.0364,  0.0439]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>)\n",
      "hidden tensor([[[ 0.0411, -0.0855,  0.1202,  ..., -0.0705, -0.0252,  0.0457],\n",
      "         [ 0.0398, -0.0865,  0.1252,  ..., -0.0714, -0.0270,  0.0415],\n",
      "         [ 0.0330, -0.0873,  0.1307,  ..., -0.0720, -0.0320,  0.0334],\n",
      "         ...,\n",
      "         [ 0.0270, -0.0762,  0.1179,  ..., -0.0772, -0.0282,  0.0388],\n",
      "         [ 0.0242, -0.0740,  0.1071,  ..., -0.0770, -0.0259,  0.0415],\n",
      "         [ 0.0182, -0.0658,  0.1128,  ..., -0.0661, -0.0364,  0.0439]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pato' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 145\u001b[0m\n\u001b[1;32m    142\u001b[0m seq2seq_model \u001b[38;5;241m=\u001b[39m Seq2Seq(encoder, decoder)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m \u001b[43mtrain_seq2seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq2seq_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Evaluate and plot\u001b[39;00m\n\u001b[1;32m    148\u001b[0m evaluate_seq2seq(seq2seq_model, X_test)\n",
      "Cell \u001b[0;32mIn[4], line 89\u001b[0m, in \u001b[0;36mtrain_seq2seq\u001b[0;34m(model, X_train, epochs, learning_rate, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     87\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 89\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, X_train\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     93\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/data/aulas/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/aulas/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, source_seq, target_seq_len, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     48\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfc_out\u001b[38;5;241m.\u001b[39mout_features\n\u001b[1;32m     49\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(target_seq_len, batch_size, output_size)\u001b[38;5;241m.\u001b[39mto(source_seq\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 51\u001b[0m hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, batch_size, output_size)\u001b[38;5;241m.\u001b[39mto(source_seq\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(target_seq_len):\n",
      "File \u001b[0;32m/data/aulas/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/aulas/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m, output)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden\u001b[39m\u001b[38;5;124m'\u001b[39m, hidden)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpato\u001b[49m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden, cell\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pato' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Define the Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        output, (hidden, cell) = self.lstm(input_seq)\n",
    "        print(output.shape, hidden.shape, cell.shape)\n",
    "        print('output', output[-1])\n",
    "        print('hidden', hidden[-1]\n",
    "        print(pato)\n",
    "        return hidden, cell\n",
    "\n",
    "# Step 2: Define the Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden, cell):\n",
    "        output, (hidden, cell) = self.lstm(input_seq, (hidden, cell))\n",
    "        prediction = self.fc_out(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Step 3: Define the Seq2Seq model class with Teacher Forcing\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source_seq, target_seq_len, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source_seq.shape[1]\n",
    "        output_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(target_seq_len, batch_size, output_size).to(source_seq.device)\n",
    "\n",
    "        hidden, cell = self.encoder(source_seq)\n",
    "\n",
    "        decoder_input = torch.zeros(1, batch_size, output_size).to(source_seq.device)\n",
    "\n",
    "        for t in range(target_seq_len):\n",
    "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            use_teacher_forcing = np.random.random() < teacher_forcing_ratio\n",
    "            decoder_input = output if not use_teacher_forcing else source_seq[t].unsqueeze(0)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# Step 4: Generate Data with multiple features\n",
    "def generate_data(seq_len=50, n_samples=1000, n_features=1):\n",
    "    X = np.linspace(0, 100, n_samples)\n",
    "    y = np.sin(X)  # Change this to any other function for experimentation\n",
    "    \n",
    "    data = []\n",
    "    for i in range(len(y) - seq_len):\n",
    "        feature_data = [np.sin(X[i:i+seq_len] + np.random.randn()*0.1) for _ in range(n_features)]\n",
    "        data.append(np.stack(feature_data, axis=-1))\n",
    "\n",
    "    data = np.array(data)\n",
    "    \n",
    "    train_size = int(0.8 * data.shape[0])\n",
    "    X_train = data[:train_size]\n",
    "    X_test = data[train_size:]\n",
    "\n",
    "    return torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Step 5: Training the Seq2Seq model\n",
    "def train_seq2seq(model, X_train, epochs=100, learning_rate=0.001, teacher_forcing_ratio=0.5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X_train.permute(1, 0, 2), X_train.shape[1], teacher_forcing_ratio)\n",
    "        \n",
    "        loss = criterion(outputs, X_train.permute(1, 0, 2))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Step 6: Evaluation with plotting\n",
    "def evaluate_seq2seq(model, X_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test.permute(1, 0, 2), X_test.shape[1], teacher_forcing_ratio=0.0)\n",
    "        predictions = predictions.permute(1, 0, 2).cpu().numpy()  # Convert to numpy for plotting\n",
    "        X_test = X_test.cpu().numpy()  # Convert to numpy for plotting\n",
    "\n",
    "        # Plot the actual and predicted sequences\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(X_test[0, :, 0], label=\"Actual Sequence (Feature 1)\", color='green')\n",
    "        plt.plot(predictions[0, :, 0], label=\"Predicted Sequence (Feature 1)\", linestyle=\":\", color='red')\n",
    "        plt.title(\"Actual vs Predicted Sequence\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # plot the actual and predicted sequences\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(X_test[0, :, 1], label=\"Actual Sequence (Feature 2)\", color='green')\n",
    "        plt.plot(predictions[0, :, 1], label=\"Predicted Sequence (Feature 2)\", linestyle=\":\", color='red')\n",
    "        plt.title(\"Actual vs Predicted Sequence\")\n",
    "        plt.xlabel(\"Time step\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Step 7: Putting it all together\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate data with multiple features\n",
    "    n_features = 10  # Number of features\n",
    "    seq_len = 50\n",
    "    X_train, X_test = generate_data(seq_len=seq_len, n_samples=1100, n_features=n_features)\n",
    "\n",
    "    # Define the model parameters\n",
    "    input_size = n_features\n",
    "    hidden_size = 64\n",
    "    output_size = n_features\n",
    "\n",
    "    # Initialize Encoder, Decoder, and Seq2Seq model\n",
    "    encoder = Encoder(input_size, hidden_size).to(device)\n",
    "    decoder = Decoder(hidden_size, output_size).to(device)\n",
    "    seq2seq_model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    train_seq2seq(seq2seq_model, X_train, epochs=200, learning_rate=0.001, teacher_forcing_ratio=0.5)\n",
    "\n",
    "    # Evaluate and plot\n",
    "    evaluate_seq2seq(seq2seq_model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
